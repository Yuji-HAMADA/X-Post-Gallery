#!/usr/bin/env python3
"""
æ—¢å­˜ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼Gistã‹ã‚‰é¡”ç‰¹å¾´ã‚’æŠ½å‡ºã—ã€å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼Gistã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦
é¡ä¼¼é¡”ã‚’å«ã‚€ãƒã‚¹ãƒˆã‚’ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼Gistã«è¿½åŠ ï¼ˆå†æ§‹ç¯‰ï¼‰ã™ã‚‹ã€‚

å„ãƒã‚¹ãƒˆã«ã¯ match_source ã‚¿ã‚°ã‚’ä»˜ä¸:
  "text" : full_text ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åãƒãƒƒãƒã§æ—¢å­˜Gistã«åéŒ²æ¸ˆã¿
  "face" : ä»Šå›ã®é¡”èªè­˜ã§æ–°è¦ç™ºè¦‹ï¼ˆface_similarity ã‚¹ã‚³ã‚¢ã‚‚ä»˜ä¸ï¼‰

ä»–ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼Gistã«å«ã¾ã‚Œã‚‹ãƒã‚¹ãƒˆã¯é™¤å¤–ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ’ä»–ï¼‰ã€‚

Usage:
    python3 scripts/retrieve_character_by_face.py -c ã‚­ãƒ£ãƒ©A
    python3 scripts/retrieve_character_by_face.py -c ã‚­ãƒ£ãƒ©A ã‚­ãƒ£ãƒ©B --threshold 0.6
    python3 scripts/retrieve_character_by_face.py -c ã‚­ãƒ£ãƒ©A -g <master_gist_id>
    python3 scripts/retrieve_character_by_face.py -c ã‚­ãƒ£ãƒ©A --max-images 0   # åˆ¶é™ãªã—
"""

import argparse
import json
import os
import subprocess
import sys
import tempfile

import numpy as np
import requests

# --- InsightFace åˆæœŸåŒ–ï¼ˆé…å»¶ãƒ­ãƒ¼ãƒ‰ï¼‰ ---
_face_app = None


def get_face_app():
    global _face_app
    if _face_app is None:
        from insightface.app import FaceAnalysis
        _face_app = FaceAnalysis(
            name='buffalo_l',
            providers=['CUDAExecutionProvider', 'CPUExecutionProvider'],
        )
        _face_app.prepare(ctx_id=0, det_size=(640, 640))
    return _face_app


# ---------------------------------------------------------------------------
# ç”»åƒå–å¾—ãƒ»é¡”æ¤œå‡º
# ---------------------------------------------------------------------------

def download_image(url: str):
    """URL ã‹ã‚‰ç”»åƒã‚’ BGR numpy é…åˆ—ã§è¿”ã™ã€‚å¤±æ•—æ™‚ã¯ Noneã€‚"""
    try:
        resp = requests.get(url, timeout=15)
        if resp.status_code != 200:
            return None
        import cv2
        arr = np.frombuffer(resp.content, np.uint8)
        return cv2.imdecode(arr, cv2.IMREAD_COLOR)
    except Exception as e:
        print(f"  [WARN] ç”»åƒDLå¤±æ•—: {e}", file=sys.stderr)
        return None


def extract_face_embeddings(img) -> list[np.ndarray]:
    """ç”»åƒã‹ã‚‰ L2 æ­£è¦åŒ–æ¸ˆã¿é¡” embedding ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™ã€‚"""
    if img is None:
        return []
    try:
        faces = get_face_app().get(img)
        result = []
        for f in faces:
            if f.embedding is None:
                continue
            norm = np.linalg.norm(f.embedding)
            if norm > 0:
                result.append(f.embedding / norm)
        return result
    except Exception as e:
        print(f"  [WARN] é¡”æ¤œå‡ºå¤±æ•—: {e}", file=sys.stderr)
        return []


def max_cosine_similarity(embedding: np.ndarray,
                           ref_embeddings: list[np.ndarray]) -> float:
    """embedding ã¨ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹å…¨ä½“ã® cosine similarity ã®æœ€å¤§å€¤ã‚’è¿”ã™ã€‚"""
    if not ref_embeddings:
        return 0.0
    return float(max(np.dot(embedding, ref) for ref in ref_embeddings))


# ---------------------------------------------------------------------------
# Gist ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆgh CLI + requestsï¼‰
# ---------------------------------------------------------------------------

def fetch_gist_raw(gist_id: str) -> tuple[str, dict]:
    """
    gh CLI ã§Gistãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€data.json ã®å†…å®¹ã‚’è¿”ã™ã€‚
    æˆ»ã‚Šå€¤: (filename, data_dict)  å¤±æ•—æ™‚ã¯ RuntimeError
    """
    result = subprocess.run(
        ['gh', 'api', f'gists/{gist_id}'],
        capture_output=True, text=True,
    )
    if result.returncode != 0:
        raise RuntimeError(f'Gistå–å¾—å¤±æ•— ({gist_id}): {result.stderr.strip()}')

    meta = json.loads(result.stdout)
    for filename in ['data.json', 'gallary_data.json']:
        file_info = meta.get('files', {}).get(filename)
        if not file_info:
            continue
        raw_url = file_info.get('raw_url')
        if not raw_url:
            continue
        resp = requests.get(raw_url, timeout=30)
        if resp.status_code == 200 and resp.text.strip():
            return filename, resp.json()
    raise RuntimeError(f'data.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ ({gist_id})')


def get_tweets(gist_data: dict, key: str) -> list[dict]:
    """users.{key}.tweets ã‚’è¿”ã™ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚ã‚Šã€‚"""
    users = gist_data.get('users', {})
    if key in users:
        return users[key].get('tweets', [])
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç›´ä¸‹ã« tweets
    return gist_data.get('tweets', [])


def get_gist_id(entry) -> str | None:
    """user_gists / character_gists ã®å€¤ï¼ˆdict ã¾ãŸã¯ stringï¼‰ã‹ã‚‰ gist_id ã‚’å–å¾—ã€‚"""
    if isinstance(entry, dict):
        return entry.get('gist_id')
    return entry if isinstance(entry, str) else None


def update_gist(gist_id: str, filename: str, data: dict) -> None:
    """æ—¢å­˜Gistã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’JSON dataã§ä¸Šæ›¸ãã€‚å¤±æ•—æ™‚ã¯ RuntimeErrorã€‚"""
    tmpdir = tempfile.mkdtemp()
    tmp_file = os.path.join(tmpdir, filename)
    try:
        with open(tmp_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        result = subprocess.run(
            ['gh', 'gist', 'edit', gist_id, '-f', filename, tmp_file],
            capture_output=True, text=True,
        )
        if result.returncode != 0:
            raise RuntimeError(f'Gistæ›´æ–°å¤±æ•— ({gist_id}): {result.stderr.strip()}')
    finally:
        if os.path.exists(tmp_file):
            os.unlink(tmp_file)
        if os.path.isdir(tmpdir):
            os.rmdir(tmpdir)


# ---------------------------------------------------------------------------
# ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ embedding æ§‹ç¯‰
# ---------------------------------------------------------------------------

def build_ref_embeddings(tweets: list[dict], max_images: int) -> list[np.ndarray]:
    """
    ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼Gistã®ãƒ„ã‚¤ãƒ¼ãƒˆã‹ã‚‰é¡” embedding ã‚’æŠ½å‡ºã—ã¦ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã‚’æ§‹ç¯‰ã€‚
    max_images: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹æœ€å¤§ç”»åƒæ•°
    """
    embeddings: list[np.ndarray] = []
    processed = 0
    for tweet in tweets:
        if processed >= max_images:
            break
        for url in tweet.get('media_urls', []):
            img = download_image(url)
            processed += 1
            embeddings.extend(extract_face_embeddings(img))
            if processed >= max_images:
                break
    return embeddings


# ---------------------------------------------------------------------------
# ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å‡¦ç†ãƒ¡ã‚¤ãƒ³
# ---------------------------------------------------------------------------

def process_character(
    char_name: str,
    master_data: dict,
    threshold: float,
    max_ref_images: int,
    max_images_per_user: int,
) -> None:
    user_gists_map = master_data.get('user_gists', {})
    character_gists_map = master_data.get('character_gists', {})

    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼Gist ID ã®ç¢ºèª
    char_entry = character_gists_map.get(char_name)
    char_gist_id = get_gist_id(char_entry) if char_entry else None
    if not char_gist_id:
        print(f'âŒ "{char_name}" ãŒ character_gists ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚')
        print(f'   å…ˆã« retrieve_character.py ã§ Gist ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚')
        return

    print(f'\n{"="*60}')
    print(f'ğŸ­ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼: {char_name}  (Gist: {char_gist_id})')
    print(f'{"="*60}')

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 1: æ—¢å­˜ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼Gistã‚’å–å¾—
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f'\n[1/5] æ—¢å­˜ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼Gistã‚’å–å¾—...')
    try:
        char_filename, char_gist_data = fetch_gist_raw(char_gist_id)
    except RuntimeError as e:
        print(f'âŒ {e}')
        return

    existing_tweets = get_tweets(char_gist_data, char_name)
    existing_ids = {t['id_str'] for t in existing_tweets if t.get('id_str')}
    print(f'  æ—¢å­˜ãƒã‚¹ãƒˆæ•°ï¼ˆtext-matchedï¼‰: {len(existing_tweets)}')

    # æ—¢å­˜ãƒ„ã‚¤ãƒ¼ãƒˆã« match_source: "text" ã‚’ä»˜ä¸ï¼ˆæœªè¨­å®šã®ã‚‚ã®ã®ã¿ï¼‰
    tagged_text: list[dict] = []
    for tweet in existing_tweets:
        t = dict(tweet)
        t.setdefault('match_source', 'text')
        tagged_text.append(t)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 2: ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹é¡” embedding æ§‹ç¯‰
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f'\n[2/5] ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹é¡”ç‰¹å¾´ã‚’æŠ½å‡ºä¸­ï¼ˆæœ€å¤§{max_ref_images}æšï¼‰...')
    ref_embeddings = build_ref_embeddings(existing_tweets, max_ref_images)
    print(f'  å–å¾— embedding æ•°: {len(ref_embeddings)}')
    if not ref_embeddings:
        print(f'âŒ é¡” embedding ãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å¯¾è±¡Gistã®ç”»åƒã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚')
        return

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 3: ä»–ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é™¤å¤–ID ã‚»ãƒƒãƒˆæ§‹ç¯‰
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f'\n[3/5] ä»–ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®é™¤å¤–IDã‚’åé›†ä¸­...')
    # è‡ªã‚­ãƒ£ãƒ©æ—¢å­˜IDã‚‚å«ã‚ã‚‹ï¼ˆface ã‚¹ã‚­ãƒ£ãƒ³ã§é‡è¤‡è¿½åŠ ã—ãªã„ãŸã‚ï¼‰
    excluded_ids: set[str] = set(existing_ids)

    for other_char, other_entry in character_gists_map.items():
        if other_char == char_name:
            continue
        other_gist_id = get_gist_id(other_entry)
        if not other_gist_id:
            continue
        try:
            _, other_data = fetch_gist_raw(other_gist_id)
            other_tweets = get_tweets(other_data, other_char)
            ids = {t['id_str'] for t in other_tweets if t.get('id_str')}
            excluded_ids |= ids
            print(f'  {other_char}: {len(ids)} IDã‚’é™¤å¤–')
        except RuntimeError as e:
            print(f'  [WARN] {other_char} ã®å–å¾—å¤±æ•—ã€ã‚¹ã‚­ãƒƒãƒ—: {e}')

    print(f'  é™¤å¤–IDåˆè¨ˆ: {len(excluded_ids)}')

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 4: å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼Gistã‚’ã‚¹ã‚­ãƒ£ãƒ³
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f'\n[4/5] å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼Gistã‚’ã‚¹ã‚­ãƒ£ãƒ³ä¸­...')
    print(f'  cosine similarity é–¾å€¤: {threshold}')
    limit_str = str(max_images_per_user) if max_images_per_user > 0 else 'åˆ¶é™ãªã—'
    print(f'  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚ãŸã‚Šæœ€å¤§ç”»åƒæ•°: {limit_str}')

    # åŒã˜Gist IDã‚’æŒã¤ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆ1åº¦ã®ãƒ•ã‚§ãƒƒãƒã§æ¸ˆã‚€ï¼‰
    gist_to_users: dict[str, list[str]] = {}
    for username, entry in user_gists_map.items():
        gid = get_gist_id(entry)
        if gid:
            gist_to_users.setdefault(gid, []).append(username)

    gist_cache: dict[str, dict | None] = {}
    face_matched: list[dict] = []
    total_gists = len(gist_to_users)

    for gi, (gid, usernames_in_gist) in enumerate(gist_to_users.items()):
        label = ', '.join(usernames_in_gist[:2])
        if len(usernames_in_gist) > 2:
            label += f' +{len(usernames_in_gist) - 2}'
        print(f'  [{gi+1:3d}/{total_gists}] {gid[:8]}... ({label})', end=' ', flush=True)

        # Gist ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ©ç”¨ï¼‰
        if gid not in gist_cache:
            try:
                _, gd = fetch_gist_raw(gid)
                gist_cache[gid] = gd
            except RuntimeError as e:
                print(f'SKIP ({e})')
                gist_cache[gid] = None
                continue

        gd = gist_cache[gid]
        if gd is None:
            print('SKIP')
            continue

        gist_found = 0
        for username in usernames_in_gist:
            tweets = get_tweets(gd, username)
            processed_images = 0

            # æœ€åˆã®1æšã«é¡”ãŒæ¤œå‡ºã•ã‚Œãªã‘ã‚Œã°ã‚¢ãƒ‹ãƒ¡/é¢¨æ™¯ã¨ã¿ãªã—ã¦ã‚¹ã‚­ãƒƒãƒ—
            first_url = next(
                (url for t in tweets for url in t.get('media_urls', [])),
                None,
            )
            if first_url is None:
                continue
            if not extract_face_embeddings(download_image(first_url)):
                continue

            for tweet in tweets:
                tid = tweet.get('id_str')
                if not tid or tid in excluded_ids:
                    continue

                # ç”»åƒã”ã¨ã«é¡”ãƒãƒƒãƒãƒ³ã‚°
                tweet_matched = False
                for url in tweet.get('media_urls', []):
                    if max_images_per_user > 0 and processed_images >= max_images_per_user:
                        break
                    img = download_image(url)
                    processed_images += 1

                    for emb in extract_face_embeddings(img):
                        sim = max_cosine_similarity(emb, ref_embeddings)
                        if sim >= threshold:
                            t = dict(tweet)
                            t['match_source'] = 'face'
                            t['face_similarity'] = round(sim, 3)
                            t.setdefault('username', username)
                            face_matched.append(t)
                            excluded_ids.add(tid)  # åŒä¸€ãƒã‚¹ãƒˆã®é‡è¤‡é˜²æ­¢
                            gist_found += 1
                            tweet_matched = True
                            break  # ã“ã®ãƒ„ã‚¤ãƒ¼ãƒˆã¯ç¢ºå®šã€æ¬¡ã®ãƒ„ã‚¤ãƒ¼ãƒˆã¸

                    if tweet_matched:
                        break  # æ¬¡ã®ç”»åƒã‚’è¦‹ã‚‹å¿…è¦ãªã—

        print(f'+{gist_found}')

    print(f'\n  æ–°è¦ face-matched ãƒã‚¹ãƒˆæ•°: {len(face_matched)}')

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 5: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼Gistã‚’å†æ§‹ç¯‰ãƒ»æ›´æ–°
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f'\n[5/5] ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼Gistã‚’å†æ§‹ç¯‰ä¸­...')
    all_tweets = tagged_text + face_matched

    # id_str ã§é‡è¤‡é™¤å»ï¼ˆtext-matched ã‚’å„ªå…ˆï¼‰
    seen: set[str] = set()
    deduped: list[dict] = []
    for t in all_tweets:
        tid = t.get('id_str')
        if tid and tid in seen:
            continue
        if tid:
            seen.add(tid)
        deduped.append(t)

    text_count = sum(1 for t in deduped if t.get('match_source') == 'text')
    face_count  = sum(1 for t in deduped if t.get('match_source') == 'face')
    print(f'  æœ€çµ‚ãƒã‚¹ãƒˆæ•°: {len(deduped)}  (text: {text_count}, face: {face_count})')

    new_content = {
        'users': {
            char_name: {
                'tweets': deduped,
            }
        }
    }

    try:
        update_gist(char_gist_id, char_filename, new_content)
        print(f'  âœ… Gist æ›´æ–°å®Œäº† ({char_gist_id})')
    except RuntimeError as e:
        print(f'  âŒ {e}')


# ---------------------------------------------------------------------------
# ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
# ---------------------------------------------------------------------------

def main():
    parser = argparse.ArgumentParser(
        description='é¡”èªè­˜ã§ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼Gistã‚’æ‹¡å¼µã™ã‚‹',
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    parser.add_argument(
        '-c', '--chars',
        nargs='+',
        required=True,
        metavar='ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å',
        help='å¯¾è±¡ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åï¼ˆè¤‡æ•°æŒ‡å®šå¯ã€å„ã‚­ãƒ£ãƒ©ã‚’é †ç•ªã«å‡¦ç†ï¼‰',
    )
    parser.add_argument(
        '-g', '--gist-id',
        default=None,
        help='ãƒã‚¹ã‚¿ãƒ¼Gist IDï¼ˆçœç•¥æ™‚ã¯ MASTER_GIST_ID ç’°å¢ƒå¤‰æ•°ï¼‰',
    )
    parser.add_argument(
        '--threshold',
        type=float,
        default=0.5,
        help='é¡”ãƒãƒƒãƒãƒ³ã‚°ã® cosine similarity é–¾å€¤ï¼ˆ0ã€œ1ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.5ï¼‰',
    )
    parser.add_argument(
        '--max-ref-images',
        type=int,
        default=100,
        help='ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹é¡”ç‰¹å¾´ã®æŠ½å‡ºã«ä½¿ã†æœ€å¤§ç”»åƒæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 100ï¼‰',
    )
    parser.add_argument(
        '--max-images',
        type=int,
        default=50,
        help='ã‚¹ã‚­ãƒ£ãƒ³æ™‚ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚ãŸã‚Šæœ€å¤§ç”»åƒæ•°ï¼ˆ0=åˆ¶é™ãªã—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 50ï¼‰',
    )
    args = parser.parse_args()

    # ãƒã‚¹ã‚¿ãƒ¼Gist ID ã®è§£æ±º
    master_gist_id = args.gist_id or os.environ.get('MASTER_GIST_ID', '')
    if not master_gist_id:
        print('âŒ ãƒã‚¹ã‚¿ãƒ¼Gist IDãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚-g ã¾ãŸã¯ MASTER_GIST_ID ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚')
        sys.exit(1)

    print(f'ğŸ” ãƒã‚¹ã‚¿ãƒ¼Gist ({master_gist_id}) ã‚’å–å¾—ä¸­...')
    try:
        _, master_data = fetch_gist_raw(master_gist_id)
    except RuntimeError as e:
        print(f'âŒ {e}')
        sys.exit(1)

    print(f'  ãƒ¦ãƒ¼ã‚¶ãƒ¼Gistæ•°: {len(master_data.get("user_gists", {}))} äºº')
    print(f'  ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼Gistæ•°: {len(master_data.get("character_gists", {}))} ã‚­ãƒ£ãƒ©')

    for char_name in args.chars:
        process_character(
            char_name=char_name,
            master_data=master_data,
            threshold=args.threshold,
            max_ref_images=args.max_ref_images,
            max_images_per_user=args.max_images,
        )

    print('\nğŸ‰ ã™ã¹ã¦å®Œäº†ï¼')


if __name__ == '__main__':
    main()
