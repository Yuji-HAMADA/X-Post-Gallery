"""
æŒ‡å®šãƒ¦ãƒ¼ã‚¶(ã¾ãŸã¯ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°)ã®ãƒã‚¹ãƒˆã‚’å–å¾—ã—ã€æ—¢å­˜Gistã«ã‚¢ãƒšãƒ³ãƒ‰ã™ã‚‹ã€‚
  - å…ˆé ­1ä»¶ã¯Gistã®å…ˆé ­ã«æŒ¿å…¥ã€æ®‹ã‚Šã¯æœ«å°¾ã«è¿½åŠ 
  - æ—¢å­˜IDãŒè¦‹ã¤ã‹ã£ãŸã‚‰å–å¾—ã‚’åœæ­¢ï¼ˆ--stop-on-existingï¼‰
  - 3ç¨®é¡ã®Gistãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¯¾å¿œ:
      master : {user_screen_name, user_gists:{user:gist_id}, tweets:[flat]}
      multi  : {users:{user:{tweets:[]}}}
      single : {user_screen_name, tweets:[]}
  - masterå½¢å¼ã§user_gistsãŒå­˜åœ¨ã™ã‚‹å ´åˆ: é–¾å€¤åˆ°é”ã§è‡ªå‹•çš„ã«ç§»å‹•å…ˆGistã‚’é¸æŠã—ç§»å‹•
    ãƒã‚¹ã‚¿ãƒ¼Gistã«ã¯ä»£è¡¨1ä»¶ï¼ˆgist_idãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä»˜ãï¼‰ã‚’æ®‹ã™
"""
import json
import os
import re
import shutil
import sys
import argparse
import subprocess
import tempfile

DATA_DIR = "data"
TWEETS_JS = os.path.join(DATA_DIR, "tweets.js")
MIGRATE_THRESHOLD = 2   # ã“ã®ä»¶æ•°ä»¥ä¸Šã«ãªã£ãŸã‚‰ç§»å‹•
GIST_MAX_TWEETS = 1000  # ç§»å‹•å…ˆGistã®ä¸Šé™

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("-g", "--gist-id", required=True, help="Appendå¯¾è±¡ã®Gist ID")
    parser.add_argument("-u", "--user", default=None, help="Target user ID (--user ã¾ãŸã¯ --hashtag ã®ã©ã¡ã‚‰ã‹å¿…é ˆ)")
    parser.add_argument("--hashtag", type=str, default=None, help="Target hashtag (#ãªã—)")
    parser.add_argument("-m", "--mode", default="post_only", choices=["all", "post_only"])
    parser.add_argument("-n", "--num", type=int, default=100, help="æœ€å¤§å–å¾—ä»¶æ•°")
    parser.add_argument("-s", "--stop-on-existing", action="store_true", help="æ—¢å­˜IDã«å½“ãŸã£ãŸã‚‰åœæ­¢ï¼ˆã‚¹ãƒˆãƒƒãƒ—ã‚ªãƒ³ãƒ¢ãƒ¼ãƒ‰ï¼‰")
    parser.add_argument("--force-empty", action="store_true", help="GistãŒ0ä»¶ã§ã‚‚å¼·åˆ¶ç¶šè¡Œï¼ˆé€šå¸¸ã¯å®‰å…¨ã®ãŸã‚ä¸­æ–­ï¼‰")
    parser.add_argument("-p", "--promote-gist-id", default=None,
                        help="ç§»å‹•å…ˆGist IDã‚’æ‰‹å‹•æŒ‡å®šï¼ˆçœç•¥æ™‚ã¯user_gistsã‹ã‚‰è‡ªå‹•é¸æŠï¼‰")
    return parser.parse_args()

# ---------------------------------------------------------------------------
# Gist ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆåˆ¤å®š
# ---------------------------------------------------------------------------

def is_master_gist_format(data):
    """ãƒã‚¹ã‚¿ãƒ¼Gistå½¢å¼: {user_gists:{...}, tweets:[flat]} ã‹ã©ã†ã‹åˆ¤å®š"""
    return isinstance(data, dict) and "user_gists" in data

def is_multi_user_format(data):
    """ãƒãƒ«ãƒãƒ¦ãƒ¼ã‚¶å½¢å¼: {users:{username:{tweets:[]}}} ã‹ã©ã†ã‹åˆ¤å®š"""
    return isinstance(data, dict) and "users" in data and not is_master_gist_format(data)

def _tweet_belongs_to_user(tweet, user):
    """ãƒ„ã‚¤ãƒ¼ãƒˆãŒæŒ‡å®šãƒ¦ãƒ¼ã‚¶ã®ã‚‚ã®ã‹ã©ã†ã‹åˆ¤å®š"""
    if f"x.com/{user}/status/" in tweet.get("post_url", ""):
        return True
    if tweet.get("full_text", "").startswith(f"@{user}:"):
        return True
    return False

def get_user_tweets(data, user):
    """ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ã®ãƒ„ã‚¤ãƒ¼ãƒˆã‚’å–å¾—ï¼ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè‡ªå‹•åˆ¤å®šï¼‰"""
    if is_master_gist_format(data):
        # flat tweetsã‹ã‚‰å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ã®ã‚‚ã®ã®ã¿æŠ½å‡º
        if not user:
            return data.get("tweets", [])
        return [t for t in data.get("tweets", []) if _tweet_belongs_to_user(t, user)]
    if is_multi_user_format(data):
        return data.get("users", {}).get(user, {}).get("tweets", [])
    # single-userå½¢å¼
    return data.get("tweets", []) if isinstance(data, dict) else (data if isinstance(data, list) else [])

# ---------------------------------------------------------------------------
# Gist å–å¾—
# ---------------------------------------------------------------------------

def _fetch_via_git_clone(gist_id, candidate_files):
    """raw_urlå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: git clone ã§Gistã‚’å–å¾—"""
    tmpdir = tempfile.mkdtemp(prefix="gist_clone_")
    try:
        result = subprocess.run(
            ["gh", "gist", "clone", gist_id, tmpdir],
            capture_output=True, text=True,
        )
        if result.returncode != 0:
            print(f"âŒ git cloneå¤±æ•—: {result.stderr}")
            sys.exit(1)
        for filename in candidate_files:
            filepath = os.path.join(tmpdir, filename)
            if os.path.exists(filepath):
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.loads(f.read(), strict=False)
                return filename, data
    except json.JSONDecodeError as e:
        print(f"âŒ JSON parse error after git clone: {e}")
        sys.exit(1)
    finally:
        shutil.rmtree(tmpdir, ignore_errors=True)
    print("âŒ No valid data found in Gist.")
    sys.exit(1)

def fetch_gist_data(gist_id):
    """Gistã‹ã‚‰JSONå–å¾—ã€‚(filename, full_data) ã‚’è¿”ã™ã€‚
    curlãŒå¤±æ•—ã—ãŸå ´åˆã¯ git clone ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚
    """
    try:
        result = subprocess.run(
            ["gh", "api", f"gists/{gist_id}"],
            capture_output=True, text=True, check=True,
        )
        gist_meta = json.loads(result.stdout)
    except (subprocess.CalledProcessError, json.JSONDecodeError) as e:
        print(f"âŒ Failed to fetch Gist metadata: {e}")
        sys.exit(1)

    candidate_files = ["data.json", "gallary_data.json"]
    files = gist_meta.get("files", {})

    for filename in candidate_files:
        if filename not in files:
            continue
        raw_url = files[filename].get("raw_url")
        if not raw_url:
            continue
        try:
            token = os.environ.get("GH_TOKEN", "")
            curl_cmd = ["curl", "-sf", "-L"]  # -f: HTTPã‚¨ãƒ©ãƒ¼æ™‚ã«å¤±æ•—æ‰±ã„
            if token:
                curl_cmd += ["-H", f"Authorization: Bearer {token}"]
            curl_cmd.append(raw_url)
            dl = subprocess.run(curl_cmd, capture_output=True, text=True)
            if dl.returncode == 0:
                data = json.loads(dl.stdout)
                return filename, data
        except json.JSONDecodeError:
            pass

    # Fallback: git clone
    print("âš ï¸  raw_urlå–å¾—å¤±æ•— â†’ git clone ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯...")
    return _fetch_via_git_clone(gist_id, candidate_files)

# ---------------------------------------------------------------------------
# ç§»å‹•å…ˆGisté¸æŠ
# ---------------------------------------------------------------------------

def select_promote_gist_from_master(full_data):
    """user_gists ã®æœ«å°¾ï¼ˆæœ€è¿‘è¿½åŠ ï¼‰ã®ä¸€æ„ãªGist IDã‚’è‡ªå‹•é¸æŠã—ã¦è¿”ã™"""
    user_gists = full_data.get("user_gists", {})
    if not user_gists:
        return None
    seen = set()
    unique_gists = []
    for gist_id in user_gists.values():
        if gist_id not in seen:
            unique_gists.append(gist_id)
            seen.add(gist_id)
    return unique_gists[-1] if unique_gists else None

# ---------------------------------------------------------------------------
# IDç®¡ç†
# ---------------------------------------------------------------------------

def get_existing_ids_ordered(tweets):
    """æ—¢å­˜tweetsã‹ã‚‰é †åºä»˜ãIDãƒªã‚¹ãƒˆã‚’æ§‹ç¯‰ï¼ˆé€£ç¶šä¸€è‡´åˆ¤å®šç”¨ï¼‰"""
    ids = []
    seen = set()
    for item in tweets:
        tid = item.get("id_str") or item.get("tweet", {}).get("id_str")
        if tid and tid not in seen:
            ids.append(tid)
            seen.add(tid)
    return ids

def write_skip_ids_file(ordered_ids):
    """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æ—¢å­˜IDã‚’é †åºä»˜ãã§æ›¸ãå‡ºã™ï¼ˆé€£ç¶šä¸€è‡´åˆ¤å®šç”¨ï¼‰"""
    fd, path = tempfile.mkstemp(suffix=".txt", prefix="skip_ids_")
    with os.fdopen(fd, 'w') as f:
        for tid in ordered_ids:
            f.write(tid + "\n")
    return path

# ---------------------------------------------------------------------------
# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
# ---------------------------------------------------------------------------

def run_extraction(user, hashtag, mode, num, skip_ids_file, stop_on_existing=True):
    """extract_media.py ã‚’å‘¼ã³å‡ºã—ã¦ãƒã‚¹ãƒˆã‚’å–å¾—"""
    cmd = [
        sys.executable, "scripts/extract_media.py",
        "--mode", mode,
        "-n", str(num),
        "--skip-ids-file", skip_ids_file,
    ]
    if user:
        cmd.extend(["-u", user])
    elif hashtag:
        cmd.extend(["--hashtag", hashtag])
    if stop_on_existing:
        cmd.append("--stop-on-existing")
    print(f"ğŸš€ Running: {' '.join(cmd)}")
    result = subprocess.run(cmd)
    if result.returncode != 0:
        print("âŒ Extraction failed.")
        sys.exit(1)

def parse_tweets_js():
    """extract_media.py ãŒå‡ºåŠ›ã—ãŸ tweets.js ã‚’èª­ã‚€"""
    if not os.path.exists(TWEETS_JS):
        print("âŒ tweets.js not found.")
        sys.exit(1)
    with open(TWEETS_JS, 'r', encoding='utf-8') as f:
        content = f.read()
    json_str = re.sub(r'^window\.YTD\.tweets\.part0\s*=\s*', '', content)
    raw_tweets = json.loads(json_str)

    converted = []
    for item in raw_tweets:
        tweet = item.get('tweet', {})
        full_text = tweet.get('full_text', '')
        media_list = tweet.get('extended_entities', {}).get('media', [])
        if not media_list:
            media_list = tweet.get('entities', {}).get('media', [])
        if not media_list:
            continue
        media_urls = [m.get('media_url_https', '') for m in media_list if m.get('media_url_https')]
        if not media_urls:
            continue

        post_url = ''
        for m in media_list:
            eu = m.get('expanded_url', '')
            if '/status/' in eu:
                post_url = re.sub(r'/photo/\d+$', '', eu)
                break

        entry = {
            'full_text': full_text,
            'created_at': tweet.get('created_at', ''),
            'media_urls': media_urls,
            'id_str': tweet.get('id_str', ''),
        }
        if post_url:
            entry['post_url'] = post_url
        converted.append(entry)

    return converted

# ---------------------------------------------------------------------------
# ãƒãƒ¼ã‚¸
# ---------------------------------------------------------------------------

def append_tweets(existing_tweets, new_tweets):
    """æ–°è¦tweetsã‚’æ—¢å­˜ã«æŒ¿å…¥: å…ˆé ­1ä»¶â†’å…ˆé ­ã€æ®‹ã‚Šâ†’æœ«å°¾"""
    if not new_tweets:
        print("â„¹ï¸ No new tweets to append.")
        return existing_tweets

    existing_ids = {t.get("id_str") for t in existing_tweets if t.get("id_str")}
    unique_new = [t for t in new_tweets if t.get("id_str") not in existing_ids]
    if not unique_new:
        print("â„¹ï¸ All tweets already exist. Nothing to append.")
        return existing_tweets

    first = unique_new[0]
    rest = unique_new[1:]
    result = [first] + existing_tweets + rest
    print(f"âœ¨ Appended: 1 to head + {len(rest)} to tail = {len(unique_new)} new tweets")
    return result

# ---------------------------------------------------------------------------
# å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰
# ---------------------------------------------------------------------------

def build_output(full_data, user, merged_tweets, user_gist_id=None):
    """æœ€çµ‚å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ã€‚å„ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ä¿æŒã™ã‚‹ã€‚
    user_gist_id ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆï¼ˆç§»å‹•å¾Œï¼‰:
      - master: flatãƒªã‚¹ãƒˆã‹ã‚‰è©²å½“ãƒ¦ãƒ¼ã‚¶ã‚’é™¤ãã€ä»£è¡¨1ä»¶ï¼ˆgist_idãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä»˜ãï¼‰ã‚’å…ˆé ­ã«è¿½åŠ 
      - multi : users[user] = {gist_id, tweets:[ä»£è¡¨1ä»¶]}
    """
    if is_master_gist_format(full_data) and user:
        updated = dict(full_data)
        # ä»–ãƒ¦ãƒ¼ã‚¶ã®ãƒ„ã‚¤ãƒ¼ãƒˆã¯ãã®ã¾ã¾ä¿æŒ
        other_tweets = [t for t in updated.get("tweets", []) if not _tweet_belongs_to_user(t, user)]
        if user_gist_id:
            # ä»£è¡¨1ä»¶ã«gist_idã‚’ä»˜ä¸ã—ã¦flatãƒªã‚¹ãƒˆã®å…ˆé ­ã¸
            representative = dict(merged_tweets[0])
            representative["gist_id"] = user_gist_id
            updated["tweets"] = [representative] + other_tweets
            # user_gists ãƒãƒƒãƒ”ãƒ³ã‚°ã«ã‚‚è¿½åŠ 
            user_gists = dict(updated.get("user_gists", {}))
            user_gists[user] = user_gist_id
            updated["user_gists"] = user_gists
        else:
            updated["tweets"] = merged_tweets + other_tweets
        return updated

    if is_multi_user_format(full_data) and user:
        updated = dict(full_data)
        users = dict(updated.get("users", {}))
        if user_gist_id:
            users[user] = {
                "gist_id": user_gist_id,
                "tweets": [merged_tweets[0]],
            }
            if "user_gists" in updated:
                user_gists = dict(updated["user_gists"])
                user_gists[user] = user_gist_id
                updated["user_gists"] = user_gists
        else:
            users[user] = {"tweets": merged_tweets}
        updated["users"] = users
        return updated

    # single-userå½¢å¼
    user_screen_name = full_data.get("user_screen_name", user or "Unknown") if isinstance(full_data, dict) else (user or "Unknown")
    return {
        "user_screen_name": user or user_screen_name,
        "tweets": merged_tweets,
    }

# ---------------------------------------------------------------------------
# Gistä½œæˆãƒ»ç§»å‹•
# ---------------------------------------------------------------------------

def create_gist_for_user(user, tweets):
    """æ–°ã—ã„Gistã‚’ä½œæˆã—ã¦ãƒ¦ãƒ¼ã‚¶ã®ãƒ„ã‚¤ãƒ¼ãƒˆã‚’æ ¼ç´ã—ã€Gist IDã‚’è¿”ã™"""
    data = {"users": {user: {"tweets": tweets}}}
    fd, tmp_file = tempfile.mkstemp(suffix=".json", prefix=f"new_gist_{user}_")
    try:
        with os.fdopen(fd, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        result = subprocess.run(
            ["gh", "gist", "create", tmp_file, "-p",
             "--filename", "data.json",
             "-d", f"Gallery Data for @{user}"],
            capture_output=True, text=True,
        )
    finally:
        if os.path.exists(tmp_file):
            os.unlink(tmp_file)

    if result.returncode != 0:
        print(f"âŒ æ–°è¦Gistä½œæˆå¤±æ•—: {result.stderr}")
        sys.exit(1)

    gist_url = result.stdout.strip().rstrip("/")
    new_gist_id = gist_url.split("/")[-1]
    return new_gist_id

def migrate_user_tweets(promote_gist_id, user, tweets):
    """ãƒ¦ãƒ¼ã‚¶ã®ãƒ„ã‚¤ãƒ¼ãƒˆã‚’ promote Gistï¼ˆã¾ãŸã¯æ–°è¦Gistï¼‰ã«ç§»å‹•ã—ã€ç§»å‹•å…ˆGist IDã‚’è¿”ã™"""
    promote_filename, promote_data = fetch_gist_data(promote_gist_id)

    if is_multi_user_format(promote_data):
        current_total = sum(
            len(u.get("tweets", [])) for u in promote_data.get("users", {}).values()
        )
    elif isinstance(promote_data, dict):
        current_total = len(promote_data.get("tweets", []))
    else:
        current_total = len(promote_data) if isinstance(promote_data, list) else 0

    print(f"ğŸ“Š ç§»å‹•å…ˆGist ({promote_gist_id[:8]}...): ç¾åœ¨ {current_total} ä»¶")

    if current_total + len(tweets) > GIST_MAX_TWEETS:
        print(f"âš ï¸  è¿½åŠ ã™ã‚‹ã¨ {GIST_MAX_TWEETS} ä»¶ã‚’è¶…ãˆã‚‹ãŸã‚ã€æ–°è¦Gistã‚’ä½œæˆã—ã¾ã™...")
        new_gist_id = create_gist_for_user(user, tweets)
        print(f"ğŸ†• æ–°è¦Gistä½œæˆ: {new_gist_id}  (@{user}: {len(tweets)} ä»¶)")
        return new_gist_id

    # æ—¢å­˜ã® promote Gist ã«è¿½åŠ 
    if is_multi_user_format(promote_data):
        updated_promote = dict(promote_data)
        users = dict(updated_promote.get("users", {}))
        users[user] = {"tweets": tweets}
        updated_promote["users"] = users
    else:
        updated_promote = {"users": {user: {"tweets": tweets}}}

    fd, tmp_file = tempfile.mkstemp(suffix=".json", prefix="promote_")
    try:
        with os.fdopen(fd, 'w', encoding='utf-8') as f:
            json.dump(updated_promote, f, ensure_ascii=False, indent=2)
        result = subprocess.run(
            ["gh", "gist", "edit", promote_gist_id, "-f", promote_filename, tmp_file],
            capture_output=True, text=True,
        )
    finally:
        if os.path.exists(tmp_file):
            os.unlink(tmp_file)

    if result.returncode != 0:
        print(f"âŒ ç§»å‹•å…ˆGistæ›´æ–°å¤±æ•—: {result.stderr}")
        sys.exit(1)

    after_total = current_total + len(tweets)
    print(f"âœ… @{user} ã‚’ Gist {promote_gist_id} ã«è¿½åŠ  ({len(tweets)} ä»¶ â†’ åˆè¨ˆ {after_total} ä»¶)")
    return promote_gist_id

# ---------------------------------------------------------------------------
# ãƒ¡ã‚¤ãƒ³
# ---------------------------------------------------------------------------

def main():
    args = parse_args()

    if not args.user and not args.hashtag:
        print("âŒ Error: --user ã¾ãŸã¯ --hashtag ã®ã©ã¡ã‚‰ã‹ãŒå¿…è¦ã§ã™ã€‚")
        sys.exit(1)

    target_label = f"#{args.hashtag}" if args.hashtag else f"@{args.user}"
    print(f"ğŸ¯ Target: {target_label}")

    # 1. æ—¢å­˜Gistãƒ‡ãƒ¼ã‚¿å–å¾—
    gist_filename, full_data = fetch_gist_data(args.gist_id)

    # 2. ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆåˆ¤å®šã¨ãƒ¦ãƒ¼ã‚¶ã®ãƒ„ã‚¤ãƒ¼ãƒˆå–å¾—
    master = is_master_gist_format(full_data)
    multi_user = is_multi_user_format(full_data)
    existing_tweets = get_user_tweets(full_data, args.user)

    if master:
        total_items = len(full_data.get("tweets", []))
        fmt_label = "master"
    elif multi_user:
        total_items = sum(len(u.get("tweets", [])) for u in full_data.get("users", {}).values())
        fmt_label = "multi-user"
    else:
        total_items = len(existing_tweets)
        fmt_label = "single-user"

    print(f"â˜ï¸ Gist: {total_items} items total, {len(existing_tweets)} for {target_label} ({fmt_label}, '{gist_filename}')")

    existing_ids_ordered = get_existing_ids_ordered(existing_tweets)
    print(f"ğŸ“‹ Existing IDs: {len(existing_ids_ordered)}")

    # æ–°è¦ãƒ¦ãƒ¼ã‚¶åˆ¤å®šï¼ˆå®‰å…¨ãƒã‚§ãƒƒã‚¯ç”¨ï¼‰
    if master:
        is_new_user = not any(_tweet_belongs_to_user(t, args.user) for t in full_data.get("tweets", [])) if args.user else False
    elif multi_user:
        is_new_user = args.user not in full_data.get("users", {})
    else:
        is_new_user = False

    # å®‰å…¨ãƒã‚§ãƒƒã‚¯: 0ä»¶ã¯ç•°å¸¸ï¼ˆæ–°è¦ãƒ¦ãƒ¼ã‚¶ã®å ´åˆã¯é™¤ãï¼‰
    if len(existing_tweets) == 0 and not args.force_empty and not is_new_user:
        print("âš ï¸  è­¦å‘Š: Gistã®Tweetæ•°ãŒ0ä»¶ã§ã™ã€‚")
        print("   Appendãƒ¢ãƒ¼ãƒ‰ãªã®ã«æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒç©ºãªã®ã¯ç•°å¸¸ãªçŠ¶æ…‹ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        print("   æ„å›³çš„ã«ç©ºã®Gistã¸Appendã—ãŸã„å ´åˆã¯ --force-empty ã‚’ä»˜ã‘ã¦å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)

    # 3. æ—¢å­˜IDãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼ˆé †åºä»˜ãï¼šé€£ç¶šä¸€è‡´åˆ¤å®šç”¨ï¼‰
    skip_ids_file = write_skip_ids_file(existing_ids_ordered)

    try:
        # 4. æ–°è¦ãƒã‚¹ãƒˆå–å¾—
        run_extraction(args.user, args.hashtag, args.mode, args.num, skip_ids_file, args.stop_on_existing)
    finally:
        os.unlink(skip_ids_file)

    # 5. å–å¾—çµæœã‚’ãƒ‘ãƒ¼ã‚¹
    new_tweets = parse_tweets_js()
    print(f"ğŸ“¥ New tweets extracted: {len(new_tweets)}")

    # 6. ã‚¢ãƒšãƒ³ãƒ‰
    merged = append_tweets(existing_tweets, new_tweets)

    # 7. ç§»å‹•å…ˆGistã®æ±ºå®š
    #    -p æ‰‹å‹•æŒ‡å®š > user_gists ã‹ã‚‰ã®è‡ªå‹•é¸æŠ > ç§»å‹•ãªã—
    promote_gist_id = args.promote_gist_id
    if not promote_gist_id and args.user and "user_gists" in full_data:
        promote_gist_id = select_promote_gist_from_master(full_data)
        if promote_gist_id:
            print(f"ğŸ” ç§»å‹•å…ˆGistã‚’è‡ªå‹•é¸æŠ: {promote_gist_id}")

    # 8. ç§»å‹•åˆ¤å®šï¼ˆé–¾å€¤åˆ°é”ã‹ã¤ç§»å‹•å…ˆãŒæ±ºå®šã—ã¦ã„ã‚‹å ´åˆï¼‰
    user_gist_id = None
    if promote_gist_id and args.user and len(merged) >= MIGRATE_THRESHOLD:
        print(f"ğŸ”„ @{args.user} ãŒ {len(merged)} ä»¶ã«é”ã—ã¾ã—ãŸï¼ˆé–¾å€¤: {MIGRATE_THRESHOLD}ï¼‰â†’ ç§»å‹•å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™")
        user_gist_id = migrate_user_tweets(promote_gist_id, args.user, merged)
        print(f"ğŸ“Œ ç§»å‹•å…ˆGist: {user_gist_id}")
        print(f"   ãƒã‚¹ã‚¿ãƒ¼Gistã«ã¯ä»£è¡¨1ä»¶ + gist_idå‚ç…§ã‚’ä¿æŒã—ã¾ã™")

    # 9. ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜
    output_file = "assets/data/data.json"
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    final_output = build_output(full_data, args.user, merged, user_gist_id=user_gist_id)
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(final_output, f, ensure_ascii=False, indent=2)

    if user_gist_id:
        print(f"ğŸ’¾ Saved: ãƒã‚¹ã‚¿ãƒ¼Gistç”¨ (ä»£è¡¨1ä»¶ + gist_id) to {output_file}")
    else:
        print(f"ğŸ’¾ Saved: {len(merged)} tweets for {target_label} to {output_file}")

    # 10. ã‚½ãƒ¼ã‚¹Gistæ›´æ–°
    print(f"â˜ï¸ Updating Gist ({args.gist_id})...")
    result = subprocess.run(
        ["gh", "gist", "edit", args.gist_id, "-f", gist_filename, output_file],
        capture_output=True, text=True,
    )
    if result.returncode == 0:
        if user_gist_id:
            print(f"âœ… Gist updated! @{args.user} â†’ {user_gist_id}")
        else:
            print(f"âœ… Gist updated successfully! Total for {target_label}: {len(merged)} tweets")
    else:
        print(f"âŒ Gist update failed: {result.stderr}")
        sys.exit(1)

if __name__ == "__main__":
    main()
