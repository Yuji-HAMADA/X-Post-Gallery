"""
ãƒ­ãƒ¼ã‚«ãƒ«ã®æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ï¼ˆForYouç­‰ï¼‰ã¨ãƒã‚¹ã‚¿ãƒ¼Gistã®æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸ã™ã‚‹ã€‚
- user_gists ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä¿æŒ
- ãƒãƒ¼ã‚¸å¾Œã€2ä»¶ä»¥ä¸Šã®ãƒ¦ãƒ¼ã‚¶ã¯ãƒ¦ãƒ¼ã‚¶Gistã«ç§»å‹•ï¼ˆé–¾å€¤åˆ°é”æ™‚ï¼‰
- ãƒã‚¹ã‚¿ãƒ¼Gistã‚’ç›´æ¥æ›´æ–°
"""
import json
import re
import argparse
import os
import sys

sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from append_to_gist import (
    fetch_gist_data,
    is_master_gist_format,
    _tweet_belongs_to_user,
    select_promote_gist_from_master,
    migrate_user_tweets,
    MIGRATE_THRESHOLD,
)

USER_PATTERN = re.compile(r"^@([^:]+):")


def extract_username(tweet):
    """ãƒ„ã‚¤ãƒ¼ãƒˆã‹ã‚‰ãƒ¦ãƒ¼ã‚¶åã‚’æŠ½å‡ºï¼ˆfull_text ã® @user: ãƒ‘ã‚¿ãƒ¼ãƒ³ or post_urlï¼‰"""
    # full_text ãƒ‘ã‚¿ãƒ¼ãƒ³
    m = USER_PATTERN.match(tweet.get("full_text", ""))
    if m:
        return m.group(1).strip()
    # post_url ãƒ‘ã‚¿ãƒ¼ãƒ³
    post_url = tweet.get("post_url", "")
    m2 = re.search(r"x\.com/([^/]+)/status/", post_url)
    if m2:
        return m2.group(1)
    return None


def group_tweets_by_user(tweets):
    """ãƒ„ã‚¤ãƒ¼ãƒˆã‚’ãƒ¦ãƒ¼ã‚¶åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–"""
    groups = {}
    for tweet in tweets:
        user = extract_username(tweet)
        key = user if user else "_unknown"
        groups.setdefault(key, []).append(tweet)
    return groups


def merge_data(gist_id, local_file):
    if not os.path.exists(local_file):
        print(f"âŒ Error: Local file {local_file} not found.")
        sys.exit(1)

    # 1. ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ (ä»Šå›å–å¾—åˆ†)
    with open(local_file, 'r', encoding='utf-8') as f:
        local_data_raw = json.load(f)

    local_tweets = []
    if isinstance(local_data_raw, dict) and "tweets" in local_data_raw:
        local_tweets = local_data_raw["tweets"]
    elif isinstance(local_data_raw, list):
        local_tweets = local_data_raw

    print(f"ğŸ“‚ Local data (New): {len(local_tweets)} items.")

    if not gist_id:
        print("â„¹ï¸ No Gist ID provided. Skipping merge.")
        return

    # 2. ãƒã‚¹ã‚¿ãƒ¼Gistãƒ‡ãƒ¼ã‚¿ã®å–å¾— (user_gists ã‚’å«ã‚€å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿)
    print(f"ğŸ” Fetching Gist data: {gist_id} ...")
    gist_filename, full_data = fetch_gist_data(gist_id)

    if full_data is None:
        print("âš ï¸ No existing data found in Gist. Treating as first run.")
        final_output = {"user_screen_name": "", "tweets": local_tweets}
        with open(local_file, 'w', encoding='utf-8') as f:
            json.dump(final_output, f, ensure_ascii=False, indent=2)
        print(f"âœ¨ Saved: {len(local_tweets)} items.")
        return

    gist_tweets = full_data.get("tweets", [])
    user_gists = dict(full_data.get("user_gists", {}))
    print(f"â˜ï¸ Gist data (Old): {len(gist_tweets)} items, {len(user_gists)} user_gists ('{gist_filename}')")

    # 3. ãƒãƒ¼ã‚¸å‡¦ç† (New + Old, é‡è¤‡æ’é™¤)
    seen_ids = set()
    merged_tweets = []

    def get_id(item):
        return item.get("id_str") or item.get("tweet", {}).get("id_str")

    # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’å…ˆã«è¿½åŠ 
    for item in local_tweets:
        tid = get_id(item)
        if tid and tid not in seen_ids:
            merged_tweets.append(item)
            seen_ids.add(tid)
    # å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å¾Œã‚ã«è¿½åŠ 
    for item in gist_tweets:
        tid = get_id(item)
        if tid and tid not in seen_ids:
            merged_tweets.append(item)
            seen_ids.add(tid)

    print(f"âœ¨ Merged Total: {len(merged_tweets)} items.")

    # 4. ãƒ¦ãƒ¼ã‚¶åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦ç§»å‹•åˆ¤å®š
    groups = group_tweets_by_user(merged_tweets)
    print(f"ğŸ‘¥ Users in merged data: {len(groups)}")

    master_tweets = []  # ãƒã‚¹ã‚¿ãƒ¼ã«æ®‹ã™ãƒ„ã‚¤ãƒ¼ãƒˆ
    migrated_count = 0

    for username, tweets in groups.items():
        if username == "_unknown":
            # ãƒ¦ãƒ¼ã‚¶ä¸æ˜ã®ãƒ„ã‚¤ãƒ¼ãƒˆã¯ãã®ã¾ã¾æ®‹ã™
            master_tweets.extend(tweets)
            continue

        if username in user_gists:
            # æ—¢ã«ãƒ¦ãƒ¼ã‚¶Gistã«ãƒãƒƒãƒ”ãƒ³ã‚°ã‚ã‚Š â†’ æ–°è¦ãƒ„ã‚¤ãƒ¼ãƒˆã‚’ãã®Gistã«è¿½åŠ 
            existing_gist_id = user_gists[username]
            # ãƒã‚¹ã‚¿ãƒ¼ã«ã‚ã‚‹æ—¢å­˜ã®ä»£è¡¨ãƒ„ã‚¤ãƒ¼ãƒˆã‚’æ¢ã™
            existing_rep = None
            new_tweets_for_user = []
            for t in tweets:
                # æ—¢å­˜Gistã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ„ã‚¤ãƒ¼ãƒˆã¯ãƒã‚¹ã‚¿ãƒ¼ã«1ä»¶ã ã‘æ®‹ã£ã¦ã„ã‚‹ä»£è¡¨
                # æ–°è¦è¿½åŠ åˆ†ã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹ã‚‚ã®
                if get_id(t) in {get_id(lt) for lt in local_tweets}:
                    new_tweets_for_user.append(t)
                else:
                    existing_rep = t

            if new_tweets_for_user:
                # æ–°è¦ãƒ„ã‚¤ãƒ¼ãƒˆã‚’ãƒ¦ãƒ¼ã‚¶Gistã«è¿½åŠ 
                print(f"ğŸ“¤ @{username}: {len(new_tweets_for_user)} new â†’ Gist {existing_gist_id[:8]}...")
                migrate_user_tweets(existing_gist_id, username, new_tweets_for_user)
                migrated_count += len(new_tweets_for_user)

            # ãƒã‚¹ã‚¿ãƒ¼ã«ã¯ä»£è¡¨1ä»¶ã‚’æ®‹ã™ï¼ˆæœ€æ–°ã®ã‚‚ã®ã‚’ä»£è¡¨ã«ï¼‰
            representative = tweets[0]  # merged ã§ã¯æ–°ã—ã„ã‚‚ã®ãŒå…ˆé ­
            representative = dict(representative)
            representative["gist_id"] = existing_gist_id
            master_tweets.append(representative)

        elif len(tweets) >= MIGRATE_THRESHOLD:
            # é–¾å€¤åˆ°é” â†’ ç§»å‹•å…ˆã‚’è‡ªå‹•é¸æŠã—ã¦ç§»å‹•
            promote_gist_id = select_promote_gist_from_master(full_data)
            if promote_gist_id:
                print(f"ğŸ”„ @{username}: {len(tweets)} tweets â†’ migrate to {promote_gist_id[:8]}...")
                actual_gist_id = migrate_user_tweets(promote_gist_id, username, tweets)
                user_gists[username] = actual_gist_id
                migrated_count += len(tweets)
                # ãƒã‚¹ã‚¿ãƒ¼ã«ã¯ä»£è¡¨1ä»¶
                representative = dict(tweets[0])
                representative["gist_id"] = actual_gist_id
                master_tweets.append(representative)
            else:
                # ç§»å‹•å…ˆãŒè¦‹ã¤ã‹ã‚‰ãªã„ â†’ ãã®ã¾ã¾æ®‹ã™
                print(f"âš ï¸ @{username}: ç§»å‹•å…ˆGistãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒã‚¹ã‚¿ãƒ¼ã«æ®‹ã—ã¾ã™ã€‚")
                master_tweets.extend(tweets)
        else:
            # 1ä»¶ã®ã¿ â†’ ãƒã‚¹ã‚¿ãƒ¼ã«ãã®ã¾ã¾æ®‹ã™
            master_tweets.extend(tweets)

    print(f"ğŸ“Š Migration: {migrated_count} tweets moved to user Gists")
    print(f"ğŸ“Š Master: {len(master_tweets)} tweets, {len(user_gists)} user_gists")

    # 5. ãƒã‚¹ã‚¿ãƒ¼Gistç”¨ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ã—ã¦ä¿å­˜
    final_output = {
        "user_screen_name": "",
        "tweets": master_tweets,
    }
    if user_gists:
        final_output["user_gists"] = user_gists

    with open(local_file, 'w', encoding='utf-8') as f:
        json.dump(final_output, f, ensure_ascii=False, indent=2)

    # 6. ãƒã‚¹ã‚¿ãƒ¼Gistã‚’æ›´æ–°
    print(f"â˜ï¸ Updating master Gist ({gist_id})...")
    import subprocess
    result = subprocess.run(
        ["gh", "gist", "edit", gist_id, "-f", gist_filename, local_file],
        capture_output=True, text=True,
    )
    if result.returncode == 0:
        print(f"âœ… Master Gist updated! {len(master_tweets)} tweets, {len(user_gists)} user_gists")
    else:
        print(f"âŒ Gist update failed: {result.stderr}")
        sys.exit(1)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--gist-id", required=True)
    parser.add_argument("--local-file", required=True)
    args = parser.parse_args()

    merge_data(args.gist_id, args.local_file)
